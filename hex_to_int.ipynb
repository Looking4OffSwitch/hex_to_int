{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a DNN to learn the mapping between a hex string and a digit string\n",
    "\n",
    "The goal is to use a Keras Sequential model to learn the mapping between a hex string (e.g. \"dbb9f\") and digit string (e.g. \"899999\"). The digit string represents the base numerical 10 value of the hex string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:08.587867Z",
     "start_time": "2017-08-30T21:16:05.537099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.activations import selu\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Methods for One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:08.630504Z",
     "start_time": "2017-08-30T21:16:08.589567Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = \"0123456789\"\n",
    "hex_digits = digits + \"abcdef\"\n",
    "\n",
    "digits_char_to_int = dict((c, i) for i, c in enumerate(digits))\n",
    "digits_int_to_char = dict((i, c) for i, c in enumerate(digits))\n",
    "\n",
    "hex_char_to_int = dict((c, i) for i, c in enumerate(hex_digits))\n",
    "hex_int_to_char = dict((i, c) for i, c in enumerate(hex_digits))\n",
    "\n",
    "# Encoding\n",
    "\n",
    "def one_hot_encode_hex_string(str):\n",
    "    int_encoded = [hex_char_to_int[c] for c in str]\n",
    "    return keras.utils.to_categorical(int_encoded, num_classes=len(hex_digits))\n",
    "\n",
    "def one_hot_encode_digits_string(str):\n",
    "    int_encoded = [digits_char_to_int[c] for c in str]\n",
    "    return keras.utils.to_categorical(int_encoded, num_classes=len(digits))\n",
    "\n",
    "# Decoding\n",
    "\n",
    "def one_hot_decode_hex_to_str(arr):\n",
    "    s = \"\"\n",
    "    for row in arr:\n",
    "        s += hex_int_to_char[np.argmax(row)]\n",
    "    return s   \n",
    "\n",
    "def one_hot_decode_digits_to_str(arr):\n",
    "    s = \"\"\n",
    "    for row in arr:\n",
    "        s += digits_int_to_char[np.argmax(row)]\n",
    "    return s   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:27:20.958431Z",
     "start_time": "2017-08-30T19:27:20.933929Z"
    }
   },
   "source": [
    "## Example hex string\n",
    "#### Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:08.640953Z",
     "start_time": "2017-08-30T21:16:08.632589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "(5, 16)\n",
      "186a2\n"
     ]
    }
   ],
   "source": [
    "# A input/hex string is *always* 5 characters\n",
    "# Range: \"186a0\" - \"dbb9f\"\n",
    "\n",
    "hex_str = \"186a2\"\n",
    "\n",
    "one_hot_encoded = one_hot_encode_hex_string(hex_str)\n",
    "print(one_hot_encoded)\n",
    "print(one_hot_encoded.shape)\n",
    "original_string = one_hot_decode_hex_to_str(one_hot_encoded)\n",
    "print(original_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example digit string\n",
    "#### Training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:08.649999Z",
     "start_time": "2017-08-30T21:16:08.642860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "(6, 10)\n",
      "100002\n"
     ]
    }
   ],
   "source": [
    "# A label/digit string is *always* 6 characters\n",
    "# Range: \"100000\" - \"899999\"\n",
    "\n",
    "digit_str = \"100002\"\n",
    "\n",
    "one_hot_encoded = one_hot_encode_digits_string(digit_str)\n",
    "print(one_hot_encoded)\n",
    "print(one_hot_encoded.shape)\n",
    "original_string = one_hot_decode_digits_to_str(one_hot_encoded)\n",
    "print(original_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:09.519148Z",
     "start_time": "2017-08-30T21:16:08.651524Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv(fname, start_num, count):\n",
    "    \"\"\"\n",
    "    Create a csv named fname containing n count.\n",
    "    Each row will contain:\n",
    "        * number (starting at start_num)\n",
    "            * incremented by 1 each row\n",
    "        * the hex value of the string version of number\n",
    "    \"\"\"\n",
    "    with open(fname, \"w+\") as f:\n",
    "        result_str = \"\"\n",
    "\n",
    "        end_num = start_num + count\n",
    "        i = start_num\n",
    "\n",
    "        while i < end_num:\n",
    "            s = str(i)\n",
    "            hex_str = hex(i)[2:] # drop the leading \"0x\"\n",
    "\n",
    "            result_str += \"{},{}\\n\".format(s, hex_str)\n",
    "            i += 1\n",
    "\n",
    "        f.write(\"string,hex\\n\")\n",
    "        f.write(result_str)\n",
    "        \n",
    "data_filename = 'data.csv'        \n",
    "\n",
    "# Create it if it doesn't already exist\n",
    "if not os.path.isfile(data_filename):\n",
    "    # from 100_000 (0x186a0) to 899_999 (0xdbb9f)\n",
    "    create_csv(data_filename, 100000, 800000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.130403Z",
     "start_time": "2017-08-30T21:16:09.521039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>560510</td>\n",
       "      <td>88d7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>516793</td>\n",
       "      <td>7e2b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753922</td>\n",
       "      <td>b8102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136933</td>\n",
       "      <td>216e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325765</td>\n",
       "      <td>4f885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   string    hex\n",
       "0  560510  88d7e\n",
       "1  516793  7e2b9\n",
       "2  753922  b8102\n",
       "3  136933  216e5\n",
       "4  325765  4f885"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_filename, dtype={'string': str, 'hex': str})\n",
    "\n",
    "# Used to test with less data\n",
    "use_full_dataset = True\n",
    "\n",
    "if not use_full_dataset:\n",
    "    df = df[0:5]\n",
    "\n",
    "# randomize rows when using the full dataset\n",
    "if use_full_dataset:\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.set_index('string')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:47:33.088284Z",
     "start_time": "2017-08-30T19:47:33.086195Z"
    }
   },
   "source": [
    "## One hot encode all hex and label strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.144767Z",
     "start_time": "2017-08-30T21:16:10.131959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 6, 10)\n",
      "(800000, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "all_labels_encoded = []\n",
    "all_hexes_encoded   = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    label_string = row[1] # row['string']\n",
    "    hex_str      = row[2] # row['hex']\n",
    "\n",
    "    label_encoded = one_hot_encode_digits_string(label_string)\n",
    "    hex_encoded   = one_hot_encode_hex_string(hex_str)\n",
    "\n",
    "    all_labels_encoded.append(label_encoded)\n",
    "    all_hexes_encoded.append(hex_encoded)\n",
    "\n",
    "all_labels_encoded = np.asarray(all_labels_encoded)\n",
    "all_hexes_encoded  = np.asarray(all_hexes_encoded)\n",
    "\n",
    "print(all_labels_encoded.shape)\n",
    "print(all_hexes_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:48:23.316727Z",
     "start_time": "2017-08-30T19:48:23.314334Z"
    }
   },
   "source": [
    "## Verify that encoding decoding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.151748Z",
     "start_time": "2017-08-30T21:16:10.146299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560510 -> 88d7e\n",
      "516793 -> 7e2b9\n",
      "753922 -> b8102\n",
      "136933 -> 216e5\n",
      "325765 -> 4f885\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(one_hot_decode_digits_to_str(all_labels_encoded[i]), \n",
    "          \"->\", \n",
    "          one_hot_decode_hex_to_str(all_hexes_encoded[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split encoded arrays into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.178956Z",
     "start_time": "2017-08-30T21:16:10.152988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total expected  : 800000\n",
      "Total calculated: 800000\n",
      "Training examples: 560000\n",
      "Validation examples: 120000\n",
      "Test examples 120000\n"
     ]
    }
   ],
   "source": [
    "if use_full_dataset:\n",
    "    example_cnt = len(df)\n",
    "    n_training_examples   = int(example_cnt * 0.7)\n",
    "    n_validation_examples = int(example_cnt * 0.15)\n",
    "    n_test_examples       = int(example_cnt * 0.15)\n",
    "else:\n",
    "    n_training_examples   = 3\n",
    "    n_validation_examples = 1\n",
    "    n_test_examples       = 1\n",
    "\n",
    "print(\"Total expected  :\", len(df))\n",
    "print(\"Total calculated:\", n_training_examples + n_validation_examples + n_test_examples)\n",
    "\n",
    "x_train = all_hexes_encoded[:n_training_examples]\n",
    "y_train = all_labels_encoded[:n_training_examples]\n",
    "print(\"Training examples:\", len(x_train))\n",
    "\n",
    "x_validation = all_hexes_encoded[n_training_examples  : n_training_examples + n_validation_examples]\n",
    "y_validation = all_labels_encoded[n_training_examples : n_training_examples + n_validation_examples]\n",
    "print(\"Validation examples:\", len(x_validation))\n",
    "\n",
    "x_test = all_hexes_encoded[len(all_hexes_encoded) - n_test_examples:]\n",
    "y_test = all_labels_encoded[len(all_labels_encoded) - n_test_examples:]\n",
    "print(\"Test examples\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of training and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.185869Z",
     "start_time": "2017-08-30T21:16:10.180818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (560000, 5, 16)\n",
      "y_train.shape: (560000, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify our dimensions match our expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.201200Z",
     "start_time": "2017-08-30T21:16:10.187691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dimensions match: True\n",
      "Label dimensions match: True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Dimensions of the input matrix: one hot encoded hex string (.e.g \"186a2\")\n",
    "#\n",
    "\n",
    "# fixed length (in chars) of a hex string\n",
    "hex_n = len(one_hot_decode_hex_to_str(all_hexes_encoded[0]))\n",
    "\n",
    "# number of symbols in the \"alphabet\" of a hex string\n",
    "hex_k = len(hex_digits)\n",
    "\n",
    "print(\"Training dimensions match:\", x_train.shape[1:3] == (hex_n, hex_k))\n",
    "\n",
    "#\n",
    "# Dimensions of the label matrix: one hot encoded digits string (.e.g \"100002\")\n",
    "#\n",
    "\n",
    "# fixed length (in chars) of a hex string\n",
    "label_n = len(one_hot_decode_digits_to_str(all_labels_encoded[0]))\n",
    "\n",
    "# number of symbols in the \"alphabet\" of a digits string\n",
    "label_k = len(digits)\n",
    "\n",
    "print(\"Label dimensions match:\", y_train.shape[1:3] == (label_n, label_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile model\n",
    "\n",
    "### Questions\n",
    "* How do we determine the correct number of nodes in the initial layer?\n",
    "* The shape of the input data is `(5, 16)` and the shape of our labels is `(6, 10)`. How do we define a model that can convert between these differing dimensions?\n",
    "* Do we have to create our own [loss function implementation](https://stackoverflow.com/questions/43576922/keras-custom-metric-iteration) to make this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.222200Z",
     "start_time": "2017-08-30T21:16:10.203035Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 5 #input size\n",
    "m = 6 #output size\n",
    "l = 16 #input alphabet size\n",
    "k = 10 #output alpahbet size\n",
    "bs = 512 #batch size\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = (n,l)))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(64, activation = selu))\n",
    "model.add(Dense(m * k, activation=None))\n",
    "model.add(Reshape((m, k)))\n",
    "\n",
    "def batch_accuracy(truth, pred):\n",
    "    truth_decoded = tf.argmax(truth, axis = 2)\n",
    "    pred_decoded = tf.argmax(pred, axis = 2)\n",
    "    correct = tf.cast(tf.equal(truth_decoded, pred_decoded), tf.float32)\n",
    "    #correct is bs x m\n",
    "    accuracy = tf.reduce_sum(correct, axis = 1)/float(m)\n",
    "    return accuracy\n",
    "\n",
    "def batch_crossentropy(truth, pred):\n",
    "    batch_size = tf.shape(truth)[0]\n",
    "    #input shapes are BxMxK where B is batchsize\n",
    "    #reshape so that every row is a separate probability distribution\n",
    "    truth = tf.reshape(truth, (-1, k))\n",
    "    pred = tf.reshape(pred, (-1, k))\n",
    "    ce = tf.nn.softmax_cross_entropy_with_logits(labels = truth, logits = pred)\n",
    "    #crossentropy is now bs * m, and we want it reshaped to bs x m\n",
    "    ce = tf.reshape(ce, (batch_size,-1))\n",
    "    loss = tf.reduce_sum(ce, axis = 1)\n",
    "    return loss\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss=batch_crossentropy,\n",
    "              metrics = [batch_accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.227412Z",
     "start_time": "2017-08-30T21:16:10.223969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "560000/560000 [==============================] - 6s - loss: 8.7050 - batch_accuracy: 0.4201 - val_loss: 7.1988 - val_batch_accuracy: 0.5134\n",
      "Epoch 2/10\n",
      "560000/560000 [==============================] - 5s - loss: 6.8147 - batch_accuracy: 0.5335 - val_loss: 6.6228 - val_batch_accuracy: 0.5438\n",
      "Epoch 3/10\n",
      "560000/560000 [==============================] - 6s - loss: 6.5566 - batch_accuracy: 0.5490 - val_loss: 6.5317 - val_batch_accuracy: 0.5511\n",
      "Epoch 4/10\n",
      "560000/560000 [==============================] - 6s - loss: 6.4620 - batch_accuracy: 0.5560 - val_loss: 6.4092 - val_batch_accuracy: 0.5597\n",
      "Epoch 5/10\n",
      "560000/560000 [==============================] - 5s - loss: 6.3328 - batch_accuracy: 0.5656 - val_loss: 6.1701 - val_batch_accuracy: 0.5738\n",
      "Epoch 6/10\n",
      "560000/560000 [==============================] - 5s - loss: 5.3782 - batch_accuracy: 0.6233 - val_loss: 4.8222 - val_batch_accuracy: 0.6589\n",
      "Epoch 7/10\n",
      "560000/560000 [==============================] - 5s - loss: 4.6533 - batch_accuracy: 0.6697 - val_loss: 4.6487 - val_batch_accuracy: 0.6674\n",
      "Epoch 8/10\n",
      "560000/560000 [==============================] - 5s - loss: 4.4706 - batch_accuracy: 0.6810 - val_loss: 4.4925 - val_batch_accuracy: 0.6780\n",
      "Epoch 9/10\n",
      "560000/560000 [==============================] - 5s - loss: 4.3933 - batch_accuracy: 0.6856 - val_loss: 4.3272 - val_batch_accuracy: 0.6899\n",
      "Epoch 10/10\n",
      "560000/560000 [==============================] - 5s - loss: 4.3490 - batch_accuracy: 0.6884 - val_loss: 4.2882 - val_batch_accuracy: 0.6920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38bc475d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size = bs, verbose = 1, epochs = 10, \n",
    "          validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Evaluate the trained model on data it has never seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T21:16:10.234299Z",
     "start_time": "2017-08-30T21:16:10.229590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118912/120000 [============================>.] - ETA: 0s\n",
      "loss    : 4.290548793411255\n",
      "accuracy: 69.20875106811523\n",
      "485130 485164\n",
      "859656 859720\n",
      "384937 384963\n",
      "192497 192507\n",
      "232498 232472\n",
      "810555 810523\n",
      "524577 524557\n",
      "838347 838359\n",
      "339155 339155\n",
      "195037 195101\n",
      "841457 841439\n",
      "627010 627070\n",
      "502015 502053\n",
      "650954 650990\n",
      "809445 809489\n",
      "720150 720114\n",
      "397210 397322\n",
      "142850 142904\n",
      "104727 104765\n",
      "782917 782915\n",
      "519725 519743\n",
      "758177 758133\n",
      "378017 378099\n",
      "378625 378695\n",
      "669155 669149\n",
      "747087 747095\n",
      "358750 358766\n",
      "150344 150366\n",
      "328150 328170\n",
      "430550 430582\n",
      "725577 725541\n",
      "188287 188279\n",
      "439550 439582\n",
      "840850 840894\n",
      "723010 723072\n",
      "252050 252074\n",
      "309276 309252\n",
      "364037 364087\n",
      "798050 798106\n",
      "436377 436341\n",
      "499855 499855\n",
      "362795 362789\n",
      "580340 580358\n",
      "763827 763875\n",
      "227441 227467\n",
      "348485 348483\n",
      "652187 652181\n",
      "466180 466108\n",
      "250555 250581\n",
      "725376 725330\n",
      "405827 405879\n",
      "785537 785607\n",
      "254624 254648\n",
      "577827 577889\n",
      "540750 540710\n",
      "654650 654654\n",
      "389655 389617\n",
      "563887 563833\n",
      "390344 390384\n",
      "212725 212799\n",
      "248150 248120\n",
      "653571 653491\n",
      "290354 290388\n",
      "441757 441727\n",
      "212695 212621\n",
      "611372 611378\n",
      "887440 887444\n",
      "554480 554444\n",
      "113920 113922\n",
      "800755 800719\n",
      "274181 274163\n",
      "709350 709386\n",
      "786720 786776\n",
      "498159 498155\n",
      "638170 638188\n",
      "396720 396712\n",
      "312750 312778\n",
      "139476 139400\n",
      "759157 759101\n",
      "683720 683722\n",
      "535117 535203\n",
      "353951 353955\n",
      "293185 293135\n",
      "427621 427645\n",
      "578285 578265\n",
      "149157 149181\n",
      "530750 530716\n",
      "405927 405931\n",
      "203190 203192\n",
      "319446 319438\n",
      "371757 371729\n",
      "693337 693377\n",
      "120450 120500\n",
      "780857 780837\n",
      "125626 125664\n",
      "702110 702202\n",
      "309650 309688\n",
      "713520 713542\n",
      "155987 156001\n",
      "320757 320703\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"\\nloss    : {}\\naccuracy: {}\".format(results[0], results[1] * 100))\n",
    "\n",
    "test_amount = 100\n",
    "output = model.predict(x_test)[0:test_amount]\n",
    "pred_digits = map(one_hot_decode_digits_to_str, output)\n",
    "truth_digits = map(one_hot_decode_digits_to_str, y_test[:test_amount])\n",
    "\n",
    "for pred, truth in zip(pred_digits, truth_digits):\n",
    "    print(pred, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
