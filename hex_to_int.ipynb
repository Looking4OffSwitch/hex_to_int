{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a DNN to learn the mapping between a hex string and a digit string\n",
    "\n",
    "The goal is to use a Keras Sequential model to learn the mapping between a hex string (e.g. \"dbb9f\") and digit string (e.g. \"899999\"). The digit string represents the base numerical 10 value of the hex string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:40:51.076511Z",
     "start_time": "2017-08-30T19:40:51.073329Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Methods for One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:27:20.932177Z",
     "start_time": "2017-08-30T19:27:20.924532Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = \"0123456789\"\n",
    "hex_digits = digits + \"abcdef\"\n",
    "\n",
    "digits_char_to_int = dict((c, i) for i, c in enumerate(digits))\n",
    "digits_int_to_char = dict((i, c) for i, c in enumerate(digits))\n",
    "\n",
    "hex_char_to_int = dict((c, i) for i, c in enumerate(hex_digits))\n",
    "hex_int_to_char = dict((i, c) for i, c in enumerate(hex_digits))\n",
    "\n",
    "# Encoding\n",
    "\n",
    "def one_hot_encode_hex_string(str):\n",
    "    int_encoded = [hex_char_to_int[c] for c in str]\n",
    "    return keras.utils.to_categorical(int_encoded, num_classes=len(hex_digits))\n",
    "\n",
    "def one_hot_encode_digits_string(str):\n",
    "    int_encoded = [digits_char_to_int[c] for c in str]\n",
    "    return keras.utils.to_categorical(int_encoded, num_classes=len(digits))\n",
    "\n",
    "# Decoding\n",
    "\n",
    "def one_hot_decode_hex_to_str(arr):\n",
    "    s = \"\"\n",
    "    for row in arr:\n",
    "        s += hex_int_to_char[np.argmax(row)]\n",
    "    return s   \n",
    "\n",
    "def one_hot_decode_digits_to_str(arr):\n",
    "    s = \"\"\n",
    "    for row in arr:\n",
    "        s += digits_int_to_char[np.argmax(row)]\n",
    "    return s   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:27:20.958431Z",
     "start_time": "2017-08-30T19:27:20.933929Z"
    }
   },
   "source": [
    "## Example hex string\n",
    "#### Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:43:55.894766Z",
     "start_time": "2017-08-30T19:43:55.886733Z"
    }
   },
   "outputs": [],
   "source": [
    "# A input/hex string is *always* 5 characters\n",
    "# Range: \"186a0\" - \"dbb9f\"\n",
    "\n",
    "hex_str = \"186a2\"\n",
    "\n",
    "one_hot_encoded = one_hot_encode_hex_string(hex_str)\n",
    "print(one_hot_encoded)\n",
    "print(one_hot_encoded.shape)\n",
    "original_string = one_hot_decode_hex_to_str(one_hot_encoded)\n",
    "print(original_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example digit string\n",
    "#### Training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:45:51.798171Z",
     "start_time": "2017-08-30T19:45:51.791876Z"
    }
   },
   "outputs": [],
   "source": [
    "# A label/digit string is *always* 6 characters\n",
    "# Range: \"100000\" - \"899999\"\n",
    "\n",
    "digit_str = \"100002\"\n",
    "\n",
    "one_hot_encoded = one_hot_encode_digits_string(digit_str)\n",
    "print(one_hot_encoded)\n",
    "print(one_hot_encoded.shape)\n",
    "original_string = one_hot_decode_digits_to_str(one_hot_encoded)\n",
    "print(original_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:47:17.189953Z",
     "start_time": "2017-08-30T19:47:16.612758Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', dtype={'string': str, 'hex': str})\n",
    "\n",
    "# Used to test with less data\n",
    "use_full_dataset = False\n",
    "\n",
    "if not use_full_dataset:\n",
    "    df = df[0:5]\n",
    "\n",
    "# randomize rows when using the full dataset\n",
    "if use_full_dataset:\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.set_index('string')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:47:33.088284Z",
     "start_time": "2017-08-30T19:47:33.086195Z"
    }
   },
   "source": [
    "## One hot encode all hex and label strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:48:07.592863Z",
     "start_time": "2017-08-30T19:48:07.579794Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels_encoded = []\n",
    "all_hexes_encoded   = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    label_string = row[1] # row['string']\n",
    "    hex_str      = row[2] # row['hex']\n",
    "\n",
    "    label_encoded = one_hot_encode_digits_string(label_string)\n",
    "    hex_encoded   = one_hot_encode_hex_string(hex_str)\n",
    "\n",
    "    all_labels_encoded.append(label_encoded)\n",
    "    all_hexes_encoded.append(hex_encoded)\n",
    "\n",
    "all_labels_encoded = np.asarray(all_labels_encoded)\n",
    "all_hexes_encoded  = np.asarray(all_hexes_encoded)\n",
    "\n",
    "print(all_labels_encoded.shape)\n",
    "print(all_hexes_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:48:23.316727Z",
     "start_time": "2017-08-30T19:48:23.314334Z"
    }
   },
   "source": [
    "## Verify that encoding decoding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:48:48.007318Z",
     "start_time": "2017-08-30T19:48:48.000655Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(one_hot_decode_digits_to_str(all_labels_encoded[i]), \n",
    "          \"->\", \n",
    "          one_hot_decode_hex_to_str(all_hexes_encoded[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split encoded arrays into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:50:02.980601Z",
     "start_time": "2017-08-30T19:50:02.960338Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_full_dataset:\n",
    "    n_training_examples   = int(example_cnt * 0.7)\n",
    "    n_validation_examples = int(example_cnt * 0.15)\n",
    "    n_test_examples       = int(example_cnt * 0.15)\n",
    "else:\n",
    "    n_training_examples   = 3\n",
    "    n_validation_examples = 1\n",
    "    n_test_examples       = 1\n",
    "\n",
    "print(\"Total expected  :\", len(df))\n",
    "print(\"Total calculated:\", n_training_examples + n_validation_examples + n_test_examples)\n",
    "\n",
    "x_train = all_hexes_encoded[:n_training_examples]\n",
    "y_train = all_labels_encoded[:n_training_examples]\n",
    "print(\"Training examples:\", len(x_train))\n",
    "\n",
    "x_validation = all_hexes_encoded[n_training_examples  : n_training_examples + n_validation_examples]\n",
    "y_validation = all_labels_encoded[n_training_examples : n_training_examples + n_validation_examples]\n",
    "print(\"Validation examples:\", len(x_validation))\n",
    "\n",
    "x_test = all_hexes_encoded[len(all_hexes_encoded) - n_test_examples:]\n",
    "y_test = all_labels_encoded[len(all_labels_encoded) - n_test_examples:]\n",
    "print(\"Test examples\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of training and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:56:13.336650Z",
     "start_time": "2017-08-30T19:56:13.333119Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify our dimensions match our expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T19:57:56.225067Z",
     "start_time": "2017-08-30T19:57:56.212819Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Dimensions of the input matrix: one hot encoded hex string (.e.g \"186a2\")\n",
    "#\n",
    "\n",
    "# fixed length (in chars) of a hex string\n",
    "hex_n = len(one_hot_decode_hex_to_str(all_hexes_encoded[0]))\n",
    "\n",
    "# number of symbols in the \"alphabet\" of a hex string\n",
    "hex_k = len(hex_digits)\n",
    "\n",
    "print(\"Training dimensions match:\", x_train.shape[1:3] == (hex_n, hex_k))\n",
    "\n",
    "#\n",
    "# Dimensions of the label matrix: one hot encoded digits string (.e.g \"100002\")\n",
    "#\n",
    "\n",
    "# fixed length (in chars) of a hex string\n",
    "label_n = len(one_hot_decode_digits_to_str(all_labels_encoded[0]))\n",
    "\n",
    "# number of symbols in the \"alphabet\" of a digits string\n",
    "label_k = len(digits)\n",
    "\n",
    "print(\"Label dimensions match:\", y_train.shape[1:3] == (label_n, label_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T04:46:48.609083Z",
     "start_time": "2017-08-30T04:46:48.496470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build and compile model\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Dense(5*16, activation='relu', input_shape=((560000,))))\n",
    "#model.add(layers.Dense(16, activation='relu', input_shape=((6 * 10,)))) 5 * 16\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=((60,))))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "#model.add(layers.Dense(n * k, activation=None))\n",
    "#model.add(layers.Reshape((n, k)))\n",
    "\n",
    "def softmaxAxis1(x):\n",
    "    return keras.activations.softmax(x, axis=1)\n",
    "# The model outputs an n by k matrix M where Mij is the probability that the ith letter is symbol j.\n",
    "# To achieve that we need to use the softmax activation along the k axis\n",
    "model.add(layers.Dense(n, activation=softmaxAxis1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "             #loss='categorical_crossentropy',\n",
    "              loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T04:46:49.827068Z",
     "start_time": "2017-08-30T04:46:49.809467Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train)#,\n",
    "                    #epochs=20,\n",
    "                    #batch_size=512)#,\n",
    "#                    validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
